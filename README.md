# ArgusCogito: Chain-of-Thought for Cross-Modal Synergy and Omnidirectional Reasoning in Camouflaged Object Segmentation

## ğŸ“‚ é¡¹ç›®ç»“æ„
```
â”œâ”€â”€ main.py                 # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ config/                 # Hydra é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â””â”€â”€ config.yaml         # ä¸»é…ç½®æ–‡ä»¶
â”œâ”€â”€ src/                    
â”‚   â”œâ”€â”€ argfocus.py         # ArgusCogito_focus (bboxç”Ÿæˆ)
â”‚   â”œâ”€â”€ knowledge.py        # Knowledge factory (çŸ¥è¯†æå–/ç”Ÿæˆ)
â”‚   â”œâ”€â”€ segment.py          # Sam4Segment (åˆ†å‰²æ¨¡å—)
â”‚   â”œâ”€â”€ prompt.py           # Prompt (æç¤ºè¯)
â”‚   â”œâ”€â”€ qwen_chat.py        # Qwen_chatï¼ˆä¸å¤§æ¨¡å‹äº¤äº’ï¼‰
â”‚   â”œâ”€â”€ arglog.py           # Arglogï¼ˆæ—¥å¿—ï¼‰
â””â”€â”€ requirements.txt        # ä¾èµ–åº“
```

---

## âš™ï¸ ç¯å¢ƒä¾èµ–
- Python >= 3.9  
- PyTorch >= 2.0 (æ”¯æŒ GPU)  
- ä¾èµ–åº“ï¼š
  ```bash
  pip install -r requirements.txt
  ```
  ä¸»è¦ä¾èµ–ï¼š
  - transformers  
  - peft  
  - Pillow  
  - hydra-core  

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. å‡†å¤‡è¾“å…¥æ•°æ®
- å°† **RGB å›¾åƒ** å’Œ **Depth å›¾åƒ** æ”¾å…¥ `config.yaml` æŒ‡å®šçš„è·¯å¾„  
- æ”¯æŒå•å¼ å›¾åƒæˆ–æ‰¹é‡å¤„ç†  

### 2. ä¿®æ”¹é…ç½®æ–‡ä»¶
åœ¨ `config/config.yaml` ä¸­è®¾ç½®ï¼š
```yaml
image: null  # image to process only

# If you specify an image, only this image will be inferred (only basename, no extention)

use_knowledge: True
use_knowledge_origin: False # use the knowledge already have
use_bboxes_origin: False

use_sam4mllm: True # use sam4mllm to provide point hints
save_knowlwdge: True
save_bboxes: True

focus_type: left_middle_right

target_long_edge: 1000
max_new_tokens: 1024

input:
  knowledge_origin: # The folder for knowledge of the images
  RGB_image: # dataset rgb image
  Depth_image: # dataset depth image

output:
  log_file: # .log file for logging
  save_file: # folder for saving visible images and masks
  save_knowledge: # folder for saving knowledge
  save_bboxes: # folder for saving bboxes

model:
  qwen2_vl_path: # model path
  sam2_ckpt: facebook/sam2.1-hiera-large # dafault path for sam2
  llava_ckpt: # model path
  sam4mllm_ckpt: /disk4/tan/SAM4MLLM-main/checkpoint/sam4mllm


rounds:
  - id: 1
    words: ['animal or human']
  - id: 2
    words: ['animal or human']


rgb_image_extention: .jpg
depth_image_extention: .png
```

### 3. è¿è¡Œ
```bash
python main.py
```

æ”¯æŒå•å¼ å›¾åƒå¤„ç†ï¼š
```bash
python main.py image=example_001
```

